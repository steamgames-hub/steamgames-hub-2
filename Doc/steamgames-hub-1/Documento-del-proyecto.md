# Steamgames-hub-1

- **Grupo:** 3 (tarde)
- **Curso escolar:** 2025/2026
- **Asignatura:** Evolución y gestión de la configuración

## Miembros del equipo (orden alfabético por apellido)

Escala 1–10 de esfuerzo/implicación (10 = mayor implicación)

| Miembro                                                                 | Implicación |
| ----------------------------------------------------------------------- | ----------- |
| [Artero Belllido, Manuel](https://github.com/Manuelgithuv)        | 10          |
| [Calderón Rodríguez, Manuel María](https://github.com/Mancalrod)            | 10          |
| [Jimenez Lara, Raimundo](https://github.com/raijimlar)            | 10          |
| [Luque Buzón, Álvaro](https://github.com/KFX5314)                  | 10          |
| [Márquez Gutiérrez, José Manuel](https://github.com/josemaMG) | 10          |
| [Salazar Caballero, Alberto](https://github.com/albertsalazar)                     | 10          |

## Enlaces de interés

- [Repositorio de código](https://github.com/steamgames-hub/steamgames-hub-1/)
- [Repositorio global del código](https://github.com/steamgames-hub/steamgames-hub/)
- [Sistema desplegado](https://steamgames-hub-1.onrender.com/)
- [Sistema global desplegado](https://steamgames-hub.onrender.com/)

## Enlace a la documentación

- [Documentación principal](https://github.com/steamgames-hub/steamgames-hub/tree/main/Doc/steamgames-hub-1)
## Indicadores del Proyecto


| Miembro del equipo                                                      | Horas | Commits | LoC   | Test                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | Issues                                                                                                       | Work Item                                                                                                                                                                                   | Dificultad     |
| ----------------------------------------------------------------------- | ----- | ------- | ----- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------- |
|[Artero Bellido, Manuel](https://github.com/Manuelgithuv)        | 60    | 62       | 22.774    | 25[¹](https://github.com/steamgames-hub/steamgames-hub-1/commit/34dd92aaefc0adc81bbf1b1c4abce0467dc67a56)                                                                                                                                                                                                                                                                                                                                                          | [5](https://github.com/steamgames-hub/steamgames-hub-1/issues?q=is%3Aissue%20assignee%3AManuelgithuv)         | [WI 104 - newdataset - Evolving uvlhub into a "[datatype]hub"](https://github.com/EGCETSII/uvlhub/issues/104) [WI 74 - Create communities](https://github.com/EGCETSII/uvlhub/issues/74)  <br>[WI 98 - Automatic dataset recommendations](https://github.com/EGCETSII/uvlhub/issues/98)</br>                           | Mandatory, Low, High |
| [Calderón Rodríguez, Manuel María](https://github.com/Mancalrod)            | 61    | 11       | 1713   | 12[¹](https://github.com/steamgames-hub/steamgames-hub-1/commit/363dd5b707fa984fa802c884a5b7bebad2a462f9)[²](https://github.com/steamgames-hub/steamgames-hub-1/commit/4ff8b41d0b7b45d1a452fe4f50fb610dfd2ae3fc)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | [2](https://github.com/steamgames-hub/steamgames-hub-1/issues?q=is%3Aissue%20assignee%3AMancalrod)           | [WI 81 - Metrics dashboard](https://github.com/EGCETSII/uvlhub/issues/81) <br>[WI 89 - Two-factor authentication (2FA)](https://github.com/EGCETSII/uvlhub/issues/89)</br>  | Low <br>High</br>   |
| [Jiménez Lara, Raimundo](https://github.com/raijimlar) | 57    | 15      | 1851  | 22[¹](https://github.com/steamgames-hub/steamgames-hub-1/commit/cdca3fffe151b2ec0e960cf50b358b5e94dc3987)[²](https://github.com/steamgames-hub/steamgames-hub-1/commit/e19b44347a064c17d411853a0debb0196f1f4cd7)                                                                                                                                                                                                                                                                | [10](https://github.com/steamgames-hub/steamgames-hub-1/issues?q=is%3Aissue%20assignee%3Araijimlar) | [WI 83 - Advanced dataset search](https://github.com/EGCETSII/uvlhub/issues/83) <br>[WI 100 - Trending datasets](https://github.com/EGCETSII/uvlhub/issues/100)</br>                             | Medium <br>Medium</br>   |
| [Luque Buzón, Álvaro](https://github.com/steamgames-hub/steamgames-hub-1/commit/e19b44347a064c17d411853a0debb0196f1f4cd7)                  | 56    | 8      | 1119  | 10[¹](https://github.com/steamgames-hub/steamgames-hub-1/commit/63d74dbbe865d440d6860f967d1b5d7d3f8ea1a5)                                                                                                                                                                                                                                                   | [4](https://github.com/steamgames-hub/steamgames-hub-1/issues?q=is%3Aissue%20assignee%3AKFX5314)            | [WI 83 - Advanced dataset search](https://github.com/EGCETSII/uvlhub/issues/83) <br>[WI 100 - Trending datasets](https://github.com/EGCETSII/uvlhub/issues/100)</br>                                 | Medium <br>Medium</br>   |
| [ Márquez Gutiérrez, José Manuel](https://github.com/josemaMG)            | 59    | 13      | 1279  | 22[¹](https://github.com/steamgames-hub/steamgames-hub-1/commit/9666abbc05a0bd12d336e63038d521174bcb9529) | [3](https://github.com/steamgames-hub/steamgames-hub-1/issues?q=is%3Aissue%20assignee%3AjosemaMG)         | [WI 81 - Metrics dashboard](https://github.com/EGCETSII/uvlhub/issues/81) <br>[WI 104 - newdataset - Evolving uvlhub into a "[datatype]hub"](https://github.com/EGCETSII/uvlhub/issues/104)</br>      | Low <br>High</br>   |
| [Salazar Caballero, Alberto](https://github.com/albertsalazar)                     | 56    | 5      | 756 | 14[¹](https://github.com/steamgames-hub/steamgames-hub-1/commit/84cf1282c74ffadd70b4b4be13f33ec8b2b1fb50)[²](https://github.com/steamgames-hub/steamgames-hub-1/commit/003b972e877bd7d151da55985bf06c82bedb60af)[³](https://github.com/steamgames-hub/steamgames-hub-1/commit/0a9062df4fde25aa97e44c6413e66632a37f2668)                                                                                                                                         | [3](https://github.com/steamgames-hub/steamgames-hub-1/issues?q=is%3Aissue%20assignee%3Aalbertsalazar)         | [WI 82 - Recover my password](https://github.com/EGCETSII/uvlhub/issues/82) <br>[WI 98 - Automatic dataset recommendations](https://github.com/EGCETSII/uvlhub/issues/98)</br> | Low <br>High</br>   |
| TOTAL                                                                   | 349   | 114      | 29.492 | 105                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | 27                                                                                                           | WIs realizados: WI 74 - Create communities, WI 81 - Metrics dashboard, WI 82 - Recover my password, WI 83 - Advanced dataset search, WI 89 - Two-factor authentication (2FA), WI 98 - Automatic dataset recommendations, WI 100 - Trending datasets, WI 104 - newdataset - Evolving uvlhub into a "[datatype]hub"                                       | H(2)/M(2)/L(3) |

La tabla contiene la información de cada miembro del proyecto y el total de la siguiente forma:

- **Horas:** número de horas empleadas en el proyecto
- **[Commits:](https://github.com/steamgames-hub/steamgames-hub-1/graphs/contributors)** solo contar los commits hechos por miembros del equipo, no lo commits previos
- **[LoC (líneas de código):](https://github.com/steamgames-hub/steamgames-hub-1/graphs/contributors)** solo contar las líneas producidas por el equipo y no las que ya existían o las que se producen al incluir código de terceros
- **Test:** solo contar los test realizados por el equipo nuevos
- **Issues:** solo contar las issues gestionadas dentro del proyecto y que hayan sido gestionadas por el equipo
- **Work Item:** principal WI del que se ha hecho cargo el miembro del proyecto
- **Dificultad:** señalar el grado de dificultad en cada caso. Además, en los totales, poner cuántos se han hecho de cada grado de dificultad entre paréntesis.

## Integración con otros equipos

### [Steamgames-hub-2](https://github.com/steamgames-hub/steamgames-hub-2)

- **Lugar (commits de integración):** integración de su trabajo dentro de nuestro proyecto para unificar el desarrollo y disponer de una plataforma común.

  - [WI-fakenodo - Fictitious service to simulate Zenodo #103](https://github.com/steamgames-hub/steamgames-hub-2/issues/31)
  - [WI 105 - Contador de descargas #105](hhttps://github.com/steamgames-hub/steamgames-hub-2/issues/3)
  - [WI 85 - Versionado mayor (nuevas versiones con DOI/identificador) #85](https://github.com/steamgames-hub/steamgames-hub-2/issues/59)
  - [WI 68 - Borradores de dataset #68](https://github.com/steamgames-hub/steamgames-hub-2/issues/26)
  - [WI 86 - Historial y visualización de versiones #86](https://github.com/steamgames-hub/steamgames-hub-2/issues/59)
  - [WI 77 - Roles de administración #77](https://github.com/steamgames-hub/steamgames-hub-2/issues/20)
  - [WI 76 - Verificación de email #76](https://github.com/steamgames-hub/steamgames-hub-2/issues/4)

## Resumen ejecutivo

### Contexto

En ciencia de datos y en el desarrollo de aplicaciones software, los datasets desempeñan un papel esencial, ya que constituyen la base para el análisis, la experimentación y la generación de conocimiento reproducible. No obstante, en la práctica es habitual encontrar fuentes de datos dispersas, incompletas, desactualizadas o de acceso limitado, lo que dificulta su reutilización, integración y explotación efectiva. Esta problemática es especialmente relevante en dominios dinámicos y masivos como el de los videojuegos.

Steamgameshub surge como respuesta a este escenario, proporcionando un dataset centralizado de juegos de Steam y una aplicación diseñada para explorar, gestionar y analizar dicha información de manera estructurada y accesible. Siguiendo principios de apertura, consistencia y reutilización, SteamGamesHub actúa como un hub que facilita el acceso a datos relevantes sobre videojuegos acercando este conocimiento tanto a usuarios finales como a desarrolladores e investigadores interesados en el ecosistema de Steam.


### Objetivo

El objetivo fue establecer una base de trabajo común para el equipo, aplicando una gestión adecuada del código y del proceso de evolución del proyecto. Para ello, se preparó el sistema para que pudiera ejecutarse de forma consistente entre miembros del equipo y se trabajó con herramientas habituales del ciclo de vida del software (reproducibilidad, automatización y despliegue), dejando el proyecto listo para incorporar funcionalidades de forma colaborativa.

### Reproducibilidad

El sistema puede ejecutarse en tres modalidades, facilitando su uso en distintos equipos y sistemas operativos:

1. **Docker Compose:** permite levantar el proyecto con una configuración común para todo el equipo.
2. **Vagrant:** como alternativa basada en máquina virtual para aislar dependencias del host y estandarizar el entorno.
3. **Ejecución local:** instalando dependencias y configurando variables/servicios necesarios.


### Trabajo realizado

Se desarrollaron mejoras centradas en descubrimiento de contenido, búsqueda avanzada, seguridad, métricas personalizadas, recomendaciones inteligentes, gestión de comunidades y extensibilidad de la plataforma, materializadas en los siguientes Work Items:

#### WI 100 - Trending datasets

Se implementó una sección de "Trending datasets" que muestra un ranking de los datasets más vistos o descargados recientemente. Esto permite a los visitantes descubrir qué contenido es popular en la plataforma. El ranking se basa en vistas/descargas de la última semana o mes, mostrando título, autor principal, comunidad (si aplica) y número de descargas/vistas.

#### WI 83 - Búsqueda avanzada de datasets

Se habilitó la búsqueda de datasets utilizando campos individuales, tanto genéricos (autor, título, etiquetas, fechas, etc.) como específicos del propio dataset. Esto permite realizar búsquedas más precisas y encontrar exactamente la información necesaria.

#### WI 89 - Autenticación de dos factores (2FA)

Se incorporó la posibilidad de habilitar un segundo factor de autenticación para proteger mejor las cuentas de usuario. Esto refuerza significativamente la seguridad del sistema ante accesos no autorizados.

#### WI 81 - Panel de métricas (Metrics dashboard)

Se desarrolló un panel personal con métricas del usuario (datasets subidos, descargas, sincronizaciones) que permite hacer seguimiento de la actividad individual en la plataforma. Esto aporta visibilidad y control sobre las contribuciones propias.

#### WI 98 - Recomendaciones automáticas de datasets

Se implementó un sistema de sugerencias de datasets relacionados al visualizar un dataset. El sistema muestra un bloque de "Datasets relacionados" basándose en autores, etiquetas o comunidades similares, priorizando los más descargados o recientes. Esto facilita el descubrimiento de contenido similar que pueda interesar al usuario.

#### WI 74 - Crear comunidades

Se añadió la funcionalidad para crear comunidades temáticas o institucionales que agrupan datasets relacionados bajo un mismo paraguas. Cada comunidad tiene nombre, descripción, curadores e identidad visual, permitiendo organizar y dar visibilidad a las contribuciones. Los datasets pueden proponerse para añadirse a una comunidad, y su inclusión está sujeta a la aceptación de los curadores.

#### WI 104 - Evolución de uvlhub hacia un "[datatype]hub"

Se reestructuró la plataforma para que no esté centrada únicamente en datasets UVL, sino que pueda manejar otros tipos de datos específicos. El objetivo es transformarla en un hub extensible donde diferentes dominios de datos puedan tener su propia lógica sin duplicar la plataforma. Cada tipo de dataset define su propio modelo heredando de una clase base común, con validaciones y lógica de negocio propias. Los flujos de carga/edición, formularios, explorador y página de detalle se construyen de forma modular y extensible.

### Calidad

Se ampliaron las pruebas automáticas y se revisó la cobertura mediante herramientas de coverage, observándose una mejora respecto al punto de partida del proyecto. Como validación funcional, se comprobó que el sistema arranca y permite ejecutar flujos básicos de extremo a extremo: registro/login (incluyendo verificación de email), gestión de permisos/roles, trabajo con borradores, consulta de historial de versiones y descargas verificando la actualización del contador y su exposición en UI/API.

### Integración

Como parte del trabajo de coordinación, se realizó integración de aportaciones externas de steamgames-hub-2 dentro del repositorio común, unificando el desarrollo y evitando divergencias entre equipos. Esta integración incorporó funcionalidades relevantes (por ejemplo, comprobación de email, contador de descargas, historial y visualización de versiones o roles de administración), dejando un único repositorio base para continuar el desarrollo. Adicionalmente, se dispone de un sistema desplegado accesible públicamente, lo que permite validar el comportamiento en un entorno desplegado y facilitar la revisión del estado del proyecto.

El sistema cuenta además con un despliegue público accesible en [steamgames-hub.onrender.com](https://steamgames-hub.onrender.com/), utilizado como evidencia de ejecución en entorno desplegado.

### Conclusión

Con esta práctica se deja el proyecto en un estado operativo y estable para el trabajo en equipo: entorno reproducible (Docker/Vagrant/local), funcionalidades principales implementadas mediante los Work Items descritos, validación mediante pruebas y verificación funcional, e integración consolidada en un único repositorio con despliegue accesible públicamente. De esta forma, el sistema queda listo para su evaluación y uso por el equipo.

## Descripción del sistema

### Visión funcional

SteamGames-Hub es un repositorio web especializado en datasets CSV relacionados con videojuegos de la plataforma Steam. El sistema permite a los usuarios cargar, previsualizar, gestionar y publicar conjuntos de datos estructurados, facilitando la colaboración y el descubrimiento de información dentro de la comunidad. A diferencia de su origen como UVLHub (centrado en modelos de características en formato UVL), esta versión ha sido completamente refactorizada para trabajar exclusivamente con archivos CSV, eliminando las referencias y dependencias del formato UVL original.

Desde el punto de vista del usuario, el sistema ofrece las siguientes funcionalidades principales:

**Gestión de usuarios y autenticación:** El módulo de autenticación (`app/modules/auth`) implementa un sistema completo de registro, login y gestión de sesiones. Los usuarios pueden registrarse proporcionando nombre, apellidos, email y contraseña. El sistema incluye verificación de email mediante tokens seguros generados, enviando correos de confirmación a través de SendGrid. Adicionalmente, se ha implementado autenticación de dos factores (2FA) que genera códigos de 6 dígitos con expiración de 5 minutos, enviados por email tras el login inicial. También existe funcionalidad de recuperación de contraseña mediante tokens de un solo uso con tiempo de expiración configurable.

**Sistema de roles:** Se define una jerarquía de roles (USER, CURATOR, ADMIN) que permite gestionar permisos diferenciados dentro de la plataforma. Los administradores pueden promover o degradar usuarios entre niveles, lo que facilita la gobernanza del contenido y el control de acceso a funcionalidades sensibles.

**Gestión de datasets:** El módulo `app/modules/dataset` constituye el núcleo funcional del sistema. Cada dataset contiene metadatos (título, descripción, categoría de datos, tags, DOI de publicación) y uno o más archivos CSV asociados. Las categorías de datos incluyen: General, Sales, User Reviews, Achievements, Playtime y Other, permitiendo clasificar los conjuntos de datos según su contenido. Los datasets pueden crearse en modo borrador, permitiendo guardar trabajo en progreso sin publicar, y posteriormente sincronizarse con servicios externos.

**Exploración y búsqueda avanzada:** El módulo `app/modules/explore` proporciona capacidades de búsqueda sofisticadas. Los usuarios pueden filtrar datasets por texto libre (buscando en títulos, descripciones, autores, afiliaciones, nombres de archivo y tags), por categoría de datos, por autor específico, por comunidad, por rango de fechas, por número mínimo de descargas o vistas, y por tags específicos. El sistema normaliza las consultas eliminando acentos y caracteres especiales para maximizar los resultados relevantes. También soporta ordenación por fecha (más recientes/antiguos), por número de descargas o por número de vistas.

**Trending datasets:** Se ha implementado una sección que muestra los datasets más populares basándose en métricas de descargas y visualizaciones recientes. Esta funcionalidad permite a los visitantes descubrir rápidamente el contenido más relevante de la plataforma, mostrando título, autor principal, comunidad asociada y estadísticas de uso.

**Recomendaciones automáticas:** Al visualizar un dataset, el sistema sugiere datasets relacionados basándose en similitud de autores, tags y comunidades, priorizando aquellos con más descargas o más recientes. Esto facilita el descubrimiento de contenido afín y mejora la experiencia de navegación.

**Comunidades:** El módulo `app/modules/community` permite crear espacios temáticos o institucionales que agrupan datasets relacionados. Cada comunidad tiene nombre, descripción, imagen identificativa y un usuario responsable (curador). Los datasets pueden proponerse para inclusión en comunidades, requiriendo aceptación del curador correspondiente. El sistema de propuestas gestiona estados (pending, accepted, rejected) y mantiene la coherencia del contenido agrupado.

**Panel de métricas:** Los usuarios disponen de un dashboard personal que muestra estadísticas de su actividad: número de datasets subidos, descargas totales de sus contenidos, sincronizaciones realizadas y otras métricas relevantes. Esto proporciona visibilidad sobre el impacto de las contribuciones individuales.

**Perfiles de usuario:** El módulo `app/modules/profile` gestiona información adicional del usuario como nombre, apellidos, afiliación institucional, ORCID y preferencias (como guardar borradores automáticamente). Esta información se utiliza para atribuir autoría en los datasets publicados.

### Arquitectura técnica

El sistema sigue una arquitectura modular basada en el patrón MVC (Modelo-Vista-Controlador), implementada sobre el framework Flask. La estructura del proyecto se organiza en dos grandes bloques:

**Capa de aplicación (`app/`):** Contiene los módulos funcionales, cada uno con su propia estructura interna consistente:
- `models.py`: Define las entidades de base de datos usando SQLAlchemy ORM
- `repositories.py`: Implementa el patrón Repository para abstracción del acceso a datos
- `services.py`: Contiene la lógica de negocio
- `routes.py`: Define los endpoints HTTP y maneja las peticiones
- `forms.py`: Define formularios WTForms para validación de entrada
- `templates/`: Plantillas Jinja2 para renderizado HTML
- `tests/`: Tests unitarios y de integración del módulo

**Capa de infraestructura (`core/`):** Proporciona componentes reutilizables y transversales:
- `blueprints/`: Clase base para blueprints de Flask
- `repositories/BaseRepository.py`: Repositorio genérico con operaciones CRUD
- `services/BaseService.py`: Servicio base con funcionalidad común
- `managers/`: Gestores de configuración, errores, logging y módulos
- `storage/`: Capa de abstracción de almacenamiento (local o AWS S3)
- `selenium/`: Utilidades para tests de interfaz

**Persistencia:** Se utiliza MariaDB como sistema gestor de base de datos, accedido mediante SQLAlchemy. Las migraciones se gestionan con Alembic (Flask-Migrate), permitiendo evolucionar el esquema de forma controlada. Los modelos principales incluyen:
- `User` y `UserProfile`: Usuarios y sus perfiles
- `DataSet` y `DSMetaData`: Datasets y sus metadatos
- `DatasetFile` y `DatasetFileMetaData`: Archivos CSV y sus metadatos
- `Author`: Autores asociados a datasets o archivos
- `Community` y `CommunityDatasetProposal`: Comunidades y propuestas
- `DSDownloadRecord` y `DSViewRecord`: Registros de descargas y visualizaciones

**Almacenamiento de archivos:** El sistema implementa una capa de almacenamiento unificada que permite trabajar tanto con sistema de archivos local (carpeta `uploads/`) como con AWS S3. La selección es transparente según las variables de entorno configuradas, facilitando el despliegue en plataformas como Render donde el almacenamiento local no es persistente.

**Integración con Fakenodo:** En lugar de depender de Zenodo para la asignación de DOIs, el sistema integra Fakenodo, un servicio simulado que replica la API de Zenodo para entornos de desarrollo y pruebas. Esto permite probar flujos de publicación sin afectar a servicios externos reales.

**API REST:** El módulo `app/modules/dataset/api.py` expone endpoints REST para acceso programático a los datasets, permitiendo integración con herramientas externas y automatización de flujos de trabajo.

### Cambios desarrollados

Los cambios implementados en este proyecto respecto al sistema base incluyen:

1. **Refactorización completa de UVL a CSV:** Eliminación de toda la lógica relacionada con modelos de características UVL, reemplazándola por gestión de archivos CSV para datos de videojuegos Steam.

2. **WI 100 - Trending datasets:** Implementación de ranking de datasets populares basado en descargas/vistas recientes.

3. **WI 83 - Búsqueda avanzada:** Extensión del explorador con filtros por múltiples campos (autor, tags, comunidad, fechas, descargas mínimas, vistas mínimas).

4. **WI 89 - Autenticación 2FA:** Sistema de doble factor de autenticación mediante códigos temporales por email.

5. **WI 81 - Dashboard de métricas:** Panel personal con estadísticas de actividad del usuario.

6. **WI 98 - Recomendaciones automáticas:** Sistema de sugerencias de datasets relacionados.

7. **WI 74 - Comunidades:** Funcionalidad completa de creación y gestión de comunidades temáticas con sistema de propuestas.

8. **WI 104 - Extensibilidad del hub:** Reestructuración para soportar diferentes tipos de datos mediante herencia de clases base.

9. **Sistema de roles:** Implementación de jerarquía USER/CURATOR/ADMIN con permisos diferenciados.

10. **Verificación de email:** Flujo de confirmación de cuenta mediante tokens seguros.

11. **Recuperación de contraseña:** Sistema de reset mediante tokens de un solo uso.

12. **Integración AWS S3:** Capa de almacenamiento compatible con servicios cloud.

## Visión global del proceso de desarrollo

### Metodología y flujo de trabajo

El desarrollo del proyecto SteamGames-Hub ha seguido una metodología ágil adaptada a las necesidades del equipo, combinando elementos de Scrum con prácticas de integración y despliegue continuos (CI/CD). El trabajo se ha organizado en torno a Work Items definidos en el repositorio principal de EGCETSII, que actúan como unidades de trabajo autocontenidas con requisitos claros.

El flujo de trabajo adoptado sigue el modelo trunk-based development con ramas de características cortas:

1. **Planificación:** Los Work Items se asignan a miembros del equipo según disponibilidad y especialización. Cada WI se descompone en tareas más pequeñas que se gestionan mediante issues en GitHub.

2. **Desarrollo en rama:** Para cada funcionalidad, se crea una rama desde `trunk` siguiendo la convención `Feature/Task.xxx`. El desarrollo se realiza de forma aislada, permitiendo trabajo paralelo sin interferencias.

3. **Commits convencionales:** Se utiliza la especificación Conventional Commits 1.0.0, reforzada mediante un hook de Git que valida el formato de los mensajes. Los tipos permitidos incluyen: feat, fix, docs, style, refactor, perf, test, build, ci, chore y revert. Ejemplo: `feat(explore): add trending datasets section`.

4. **Merge revisión:** Una vez completada la funcionalidad se hace un push, el revisor se baja los cambios, hace testing y cuando termine mergea los cambios a trunk. Finalmente se ejecutan los CI de testing para ver si funcionan. Y si ha ido bien se hace un merge a main y se suben los cambios.

5. **Integración continua:** Cada push y PR dispara los workflows de GitHub Actions configurados:
   - `CI_pytest.yml`: Ejecuta la suite de tests unitarios e integración
   - `CI_lint.yml`: Verifica el cumplimiento de estándares de código
   - `CI_selenium.yml`: Ejecuta tests de interfaz de usuario
   - `CI_codacy_analysis.yml`: Análisis estático de calidad de código
   - `CI_Codacy`: Ejecuta un coverage y lo sube a codacy.


6. **Despliegue continuo:** Los cambios en `main` disparan automáticamente el despliegue a Render mediante `CD_render_production.yml`, que primero ejecuta los tests y luego invoca el webhook de deploy. Lo mismo para desplegar en preprodución pero para la rama `Trunk` y el workflow `CD_render_preproduction.yml`.

### Herramientas utilizadas

**Control de versiones:** Git como sistema de control de versiones distribuido, con GitHub como plataforma de alojamiento. Se utilizan GitHub Issues para seguimiento de tareas, GitHub Projects para visualización kanban, y GitHub Actions para automatización.

**Entorno de desarrollo:** Visual Studio Code como editor principal, con extensiones para Python, Docker y Git. Se configuran archivos `.vscode/` compartidos para mantener consistencia entre desarrolladores.

**Gestión de dependencias:** pip con `requirements.txt` para dependencias Python. El archivo `pyproject.toml` define la configuración del proyecto y herramientas de desarrollo (black, isort, flake8).

**Contenedorización:** Docker y Docker Compose para crear entornos reproducibles. Se proporcionan configuraciones para desarrollo (`docker-compose.dev.yml`) y producción (`docker-compose.prod.yml`).

**Base de datos:** MariaDB 12.x como SGBD, con Flask-Migrate/Alembic para migraciones de esquema.

**Testing:** pytest como framework de testing, con coverage para métricas de cobertura. Selenium para tests de interfaz con navegadores Chrome y Firefox en contenedores.

**Calidad de código:** Codacy para análisis estático continuo, flake8 para linting, black para formateo automático, isort para ordenación de imports.

**Comunicación:** Discord para comunicación del equipo, con canales específicos para desarrollo, incidencias y coordinación.

### Ejemplo de ciclo completo de cambio

Supongamos que se requiere añadir la funcionalidad de "datasets favoritos" donde los usuarios puedan marcar datasets para acceso rápido. El ciclo completo sería:

**1. Definición del requisito:**
Se crea una issue en GitHub describiendo la funcionalidad: "Como usuario autenticado, quiero poder marcar datasets como favoritos para encontrarlos fácilmente". Se etiqueta como enhancement y se asigna a un desarrollador.

**2. Creación de rama:**
```bash
git checkout trunk
git pull origin trunk
git checkout -b Feature/Task.XXX
```

**3. Desarrollo del modelo:**
Se crea el modelo `UserFavorite` en un nuevo archivo o se añade a `app/modules/dataset/models.py`:
```python
class UserFavorite(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    user_id = db.Column(db.Integer, db.ForeignKey("user.id"), nullable=False)
    dataset_id = db.Column(db.Integer, db.ForeignKey("data_set.id"), nullable=False)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
```

**4. Migración de base de datos:**
```bash
flask db migrate -m "Add user favorites table"
flask db upgrade
```

**5. Implementación de repositorio y servicio:**
Se añaden métodos en el repositorio para añadir/eliminar/listar favoritos, y se crea la lógica de negocio en el servicio correspondiente.

**6. Creación de rutas:**
Se definen endpoints en `routes.py`:
- `POST /dataset/<id>/favorite` - Añadir a favoritos
- `DELETE /dataset/<id>/favorite` - Eliminar de favoritos
- `GET /profile/favorites` - Listar favoritos del usuario

**7. Desarrollo de tests:**
```python
def test_add_favorite(test_client, auth_user):
    response = test_client.post("/dataset/1/favorite")
    assert response.status_code == 200
    
def test_list_favorites(test_client, auth_user):
    response = test_client.get("/profile/favorites")
    assert response.status_code == 200
```

**8. Commits incrementales:**
```bash
git add app/modules/dataset/models.py
git commit -m "feat(dataset): add UserFavorite model"

git add migrations/
git commit -m "feat(dataset): add favorites migration"

git add app/modules/dataset/services.py app/modules/dataset/repositories.py
git commit -m "feat(dataset): implement favorites service and repository"

git add app/modules/dataset/routes.py
git commit -m "feat(dataset): add favorites endpoints"

git add app/modules/dataset/tests/
git commit -m "test(dataset): add favorites unit tests"
```

**9. Push y Pull Request:**
```bash
git push origin Feature/Task.xxx
```

**10. Revisión de CI:**
Los workflows automáticos ejecutan tests, linting y análisis. Si alguno falla, se corrige y se hace push de nuevo.

**11. Code Review:**
Un compañero revisa el código, sugiere mejoras si las hay. Se implementan los cambios solicitados.

**12. Merge:**
Una vez aprobado, se hace un merge a las ramas Trunk, y si los CI han ido bien luego a main.

**13. Despliegue:**
Los push a Trunk y a main disparan los workflows de despliegue a preproducción y a producción consecutivamente. 

**14. Verificación:**
Se accede al sistema desplegado para verificar que la funcionalidad funciona correctamente en el entorno real.

## Entorno de desarrollo

### Requisitos del sistema

El desarrollo de SteamGames-Hub requiere los siguientes componentes base:

**Sistema operativo:** El proyecto se ha desarrollado y probado principalmente en Ubuntu 22.04/24.04 LTS. También es compatible con Windows 10/11 (usando WSL2) y macOS. La mayoría de miembros del equipo han utilizado distribuciones Linux, aunque algunos han trabajado con Windows mediante Docker.

**Python:** Versión 3.12 o superior. El proyecto utiliza características modernas de Python como type hints, dataclasses y el operador walrus. La versión se especifica en `pyproject.toml` con `requires-python = ">=3.12"`.

**Base de datos:** MariaDB 12.x como sistema gestor de base de datos. En desarrollo local se requiere tener el servicio instalado y configurado. En Docker, se proporciona un contenedor preconfigurado.

**Docker (opcional pero recomendado):** Docker Engine 24.x y Docker Compose v2 para ejecutar el entorno completo en contenedores.

### Instalación local

Para configurar el entorno de desarrollo local sin Docker:

**1. Clonar el repositorio:**
```bash
git clone https://github.com/steamgames-hub/steamgames-hub-1.git
cd steamgames-hub-1
```

**2. Instalar MariaDB:**
```bash
sudo apt update
sudo apt install mariadb-server -y
sudo mysql_secure_installation
```

**3. Crear bases de datos:**
```bash
sudo mysql -e "CREATE DATABASE IF NOT EXISTS steamgameshubdb;"
sudo mysql -e "CREATE DATABASE IF NOT EXISTS steamgameshubdb_test;"
sudo mysql -e "CREATE USER IF NOT EXISTS 'steamgameshubdb_user'@'localhost' IDENTIFIED BY 'steamgameshubdb_password';"
sudo mysql -e "GRANT ALL PRIVILEGES ON steamgameshubdb.* TO 'steamgameshubdb_user'@'localhost';"
sudo mysql -e "GRANT ALL PRIVILEGES ON steamgameshubdb_test.* TO 'steamgameshubdb_user'@'localhost';"
sudo mysql -e "FLUSH PRIVILEGES;"
```

**4. Configurar entorno virtual:**
```bash
python3.12 -m venv venv
source venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
pip install -e ./
```

**5. Configurar variables de entorno:**
```bash
cp .env.local.example .env
# Editar .env con los valores apropiados
```

Las variables críticas incluyen:
- `MARIADB_HOSTNAME`, `MARIADB_PORT`, `MARIADB_USER`, `MARIADB_PASSWORD`
- `SECRET_KEY`, `SECURITY_PASSWORD_SALT`
- `SENDGRID_API_KEY`, `FROM_EMAIL` (para envío de correos)
- `FLASK_ENV=development`

**6. Inicializar base de datos:**
```bash
flask db upgrade
rosemary db:seed --reset -y
```

**7. Ejecutar aplicación:**
```bash
flask run --host=0.0.0.0 --reload --debug
```

La aplicación estará disponible en `http://localhost:5000`.

### Instalación con Docker

Para un entorno completamente contenedorizado:

**1. Clonar y configurar:**
```bash
git clone https://github.com/steamgames-hub/steamgames-hub-1.git
cd steamgames-hub-1
cp .env.docker.example .env
```

**2. Construir y levantar:**
```bash
docker compose -f docker/docker-compose.dev.yml up --build
```

Esto levanta los siguientes servicios:
- `web`: Aplicación Flask con hot-reload
- `db`: MariaDB con datos persistentes
- `nginx`: Servidor web en puerto 80
- `selenium-hub`, `selenium-chrome`, `selenium-firefox`: Grid de Selenium para tests UI

La aplicación estará disponible en `http://localhost`.

### Instalación con Vagrant

Para entornos totalmente aislados mediante máquina virtual:

**1. Requisitos previos:**
- VirtualBox 7.x instalado
- Vagrant 2.4.x instalado

**2. Levantar máquina:**
```bash
cd vagrant
vagrant up
```

La provisión automática instala todas las dependencias y configura el sistema completo.

### Versiones de dependencias principales

| Componente | Versión |
|------------|---------|
| Python | 3.12+ |
| Flask | 3.1.1 |
| SQLAlchemy | (via Flask-SQLAlchemy 3.1.1) |
| MariaDB | 12.0.2 |
| Nginx | 1.29.1 |
| Selenium | latest |
| pytest | (última estable) |
| black | 25.1.0 |
| flake8 | 7.3.0 |

### Configuración de hooks de Git

Para activar la validación de Conventional Commits:

```bash
bash scripts/setup-git-hooks.sh
```

Esto configura `.githooks/` como directorio de hooks, activando la validación automática de mensajes de commit.

### Diferencias entre entornos de desarrollo del equipo

La mayoría del equipo ha trabajado con Ubuntu 22.04/24.04 usando el entorno Docker, lo que ha garantizado consistencia. Algunos miembros han utilizado:
- **Windows + WSL2 + Docker Desktop:** Funciona correctamente, requiere habilitar integración WSL2 en Docker Desktop.
- **Ejecución local directa:** Utilizada para depuración rápida, requiere MariaDB instalado localmente.

Para evitar problemas de compatibilidad, se recomienda Docker como entorno principal de desarrollo.

## Ejercicio de propuesta de cambio

### 1. Información general

| Campo | Valor |
|-------|-------|
| **Proyecto** | SteamGames Hub |
| **Tipo de cambio** | Modificación de funcionalidad |
| **Módulo afectado** | Explore (Búsqueda avanzada) |

---

### 2. Descripción del cambio

**Cambio solicitado:** Modificar el filtro de búsqueda avanzada para cambiar el criterio de **descargas mínimas** (`min_downloads`) por **descargas máximas** (`max_downloads`).

**Justificación:** Adaptar la funcionalidad de filtrado para permitir a los usuarios buscar datasets que no superen un número máximo de descargas.

---

### 3. Cambios específicos

#### Funcionalidad
- Cambiar nombres de variables min_downloads a max_downloads, y la descripcion del filtro en el HTML. Cambiar ademas el signo de la logica de la busqueda.

#### Test unitario (nuevo)
- Añadir test que verifique que al establecer `max_downloads` con un valor determinado, no aparecen datasets que superen ese límite

---

### 4. Distribución de tareas

| Paso | Tarea | Responsable | Descripción detallada |
|------|-------|-------------|----------------------|
| **1** | Crear Issue, asignar y crear rama | **Manuel Artero** | Crear issue en el repositorio describiendo el cambio, asignar a los miembros correspondientes y crear la rama de trabajo (ej: `feature/Task.XXX`) |
| **2** | Implementar cambios en el código | **Rai** | Modificar los archivos necesarios según las especificaciones técnicas |
| **3** | Implementar test unitario | **Álvaro** | Crear test en `test_unit.py` que verifique que datasets con descargas superiores al máximo establecido no aparecen en resultados |
| **4** | Testear y comprobar funcionalidad | **José Manuel** | Ejecutar tests unitarios, realizar pruebas manuales de la funcionalidad y verificar que el filtro funciona correctamente |
| **5** | Merge y eliminar rama | **Alberto** | Realizar merge de la rama a `main`, resolver posibles conflictos y eliminar la rama de trabajo |
| **6** | Verificar en producción | **Manuel Calderón** | Desplegar en producción y verificar que la funcionalidad opera correctamente en el entorno productivo |

---

### 5. Criterios de aceptación

- Todas las referencias a `min_downloads` han sido reemplazadas por `max_downloads`
- El operador de comparación ha sido cambiado de `>=` a `<=`
- El label del formulario muestra "Max downloads" en lugar de "Min downloads"
- El test unitario verifica que no aparecen datasets con descargas superiores al máximo
- Todos los tests existentes siguen pasando
- La funcionalidad opera correctamente en producción

---

## 8. Plantilla de Issue sugerida

### Título
Cambiar filtro de búsqueda: min_downloads → max_downloads

### Descripción
Modificar el filtro de búsqueda avanzada para reemplazar el criterio de descargas mínimas por descargas máximas.

### Tareas
- [ ] Modificar `repositories.py` - Cambiar parámetro y operador
- [ ] Modificar `routes.py` - Actualizar payload
- [ ] Modificar `scripts.js` - Actualizar variables JS
- [ ] Modificar `index.html` - Actualizar formulario
- [ ] Añadir test unitario
- [ ] Verificar funcionalidad
- [ ] Merge a main
- [ ] Verificar en producción

### Asignados
@ManuelArtero @Rai @Alvaro @JoseManuel @Alberto @ManuelCalderon

### Labels
enhancement, frontend, backend, testing

---

## 9. Nombre de rama sugerido
- feature/Task.XXX donde XXX es el identificador de la issue creada.

## Conclusiones y trabajo futuro

### Conclusiones

El desarrollo de SteamGames-Hub ha permitido al equipo aplicar de forma práctica los conceptos fundamentales de evolución y gestión de la configuración en un proyecto de software real. Las principales conclusiones extraídas son:

**Importancia de la reproducibilidad:** Disponer de múltiples opciones de entorno (Docker, Vagrant, local) ha sido crucial para que todos los miembros del equipo puedan trabajar de forma consistente independientemente de su sistema operativo o configuración local. Docker Compose se ha revelado como la opción más práctica para el desarrollo diario, mientras que la documentación de instalación local ha sido útil para depuración y comprensión profunda del sistema.

**Valor de la automatización CI/CD:** La configuración de pipelines de integración y despliegue continuos ha reducido significativamente el tiempo dedicado a tareas repetitivas y ha aumentado la confianza en los cambios realizados. Los tests automáticos actúan como red de seguridad, permitiendo refactorizaciones y nuevas funcionalidades sin temor a romper funcionalidad existente.

**Beneficios de los Conventional Commits:** Adoptar una convención estricta para mensajes de commit ha mejorado la legibilidad del historial y facilitado la generación de changelogs. El hook de validación garantiza el cumplimiento sin esfuerzo adicional por parte de los desarrolladores.

**Arquitectura modular:** La estructura por módulos funcionales (auth, dataset, explore, community, profile) ha facilitado la división del trabajo y reducido conflictos de merge. Cada módulo encapsula su lógica, modelos, rutas y tests, permitiendo desarrollo paralelo eficiente.

**Integración entre equipos:** La coordinación con steamgames-hub-2 ha demostrado la importancia de establecer convenciones comunes y puntos de integración claros. La fusión de aportaciones de ambos equipos en un repositorio común ha requerido comunicación constante y resolución cuidadosa de conflictos.

**Despliegue en la nube:** El uso de Render como plataforma de despliegue ha proporcionado un entorno de producción accesible para validación y demostración, aunque ha presentado desafíos como la no persistencia del sistema de archivos local, resuelta mediante integración con AWS S3.

### Trabajo futuro

Para futuras iteraciones del proyecto, se proponen las siguientes mejoras y extensiones:

**Mejoras funcionales:**
- **Sistema de notificaciones:** Implementar notificaciones en tiempo real (via WebSockets) para informar a usuarios sobre nuevas valoraciones, comentarios o aceptación de propuestas a comunidades.
- **Comentarios en datasets:** Permitir a usuarios dejar comentarios y discusiones en los datasets, fomentando la colaboración.
- **Exportación en múltiples formatos:** Añadir capacidad de exportar datasets a formatos adicionales (JSON, Parquet, Excel) además de CSV.
- **Versionado de archivos:** Implementar control de versiones a nivel de archivo individual, no solo de dataset completo.
- **API GraphQL:** Complementar la API REST con una interfaz GraphQL para consultas más flexibles.

**Mejoras técnicas:**
- **Caché distribuida:** Implementar Redis para cachear consultas frecuentes (trending, recomendaciones) y mejorar rendimiento.
- **Búsqueda con Elasticsearch:** Migrar la búsqueda de texto a Elasticsearch para capacidades más avanzadas (fuzzy matching, relevancia, facetas).
- **Internacionalización (i18n):** Añadir soporte multiidioma para la interfaz de usuario.
- **PWA:** Convertir la aplicación en Progressive Web App para uso offline y mejor experiencia móvil.
- **Monitorización:** Integrar herramientas de observabilidad (Prometheus, Grafana, Sentry) para detección temprana de problemas.

**Mejoras de proceso:**
- **Tests de carga:** Implementar tests con Locust para validar rendimiento bajo carga.
- **Feature flags:** Añadir sistema de feature flags para despliegues graduales y A/B testing.
- **Documentación API:** Generar documentación automática de la API con OpenAPI/Swagger (ya parcialmente implementado con Flasgger).
- **Semantic versioning:** Implementar versionado semántico automático basado en Conventional Commits.

**Mejoras de seguridad:**
- **Rate limiting:** Implementar limitación de peticiones para prevenir abuso de la API.
- **Auditoría:** Registrar acciones sensibles (cambios de rol, eliminaciones) para trazabilidad.
- **HTTPS forzado:** Garantizar que todas las conexiones sean seguras en producción.
- **Escaneo de vulnerabilidades:** Integrar herramientas como Trivy o Snyk en el pipeline CI.

El proyecto queda en un estado funcional y extensible, con una base sólida para continuar su evolución en futuros cursos académicos o como proyecto de código abierto.